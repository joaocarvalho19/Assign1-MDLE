{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a765cf5-c613-4e78-93f1-bbf84d7662f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d04073a9-2b55-4f75-a93d-a93872e0830a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(master='local', appName=\"Assignment1_E2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03965d45-8bad-4ff4-b84c-3806d72d2547",
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGE_PRIME = 4294967311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "bc963414-60b7-4fbe-b28d-38ce769242d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.textFile(\"assign1/data/small_plot_sum.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "f7dddfd4-4eda-4469-9b18-beffd2d4473f",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_baskets = data.map(lambda line: re.split('\\t', line.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "27970ab8-c5e4-4430-8e78-70ae053f673f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_baskets.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c6bdbc-0056-405c-8d98-4957739481af",
   "metadata": {},
   "source": [
    "# Shingling --> min Hashing --> LSH = Candidate pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "2022b4d8-ac67-403f-9f03-11f8e47afabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Receive a document and return a set of shingles \n",
    "'''\n",
    "def shingling(doc, k=8):\n",
    "    shingles = []\n",
    "    for i in range(len(doc[1]) - k + 1):\n",
    "        shingles.append(doc[1][i:i+k])\n",
    "        \n",
    "    return (doc[0],set(shingles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7472dbd9-df52-4ef1-866b-c97d5d029585",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_shingles = item_baskets.map(shingling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1f1801a6-9ae9-49e1-9c8b-8696aafe6da9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_shingles.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f7028c4d-692d-4180-95e1-c0ead83c8ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min Hashing\n",
    "\n",
    "# specify the length of each minhash vector\n",
    "N = 128\n",
    "#max_val = (2**32)-1\n",
    "max_val = 500\n",
    "\n",
    "# create N tuples that will serve as permutation functions\n",
    "# these permutation values are used to hash all input sets\n",
    "perms = [ (random.randint(0,max_val), random.randint(0,max_val)) for i in range(N)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "725c4842-d685-4136-b6fb-dd8eb3ad04e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Given a set `doc_shingles`, pass each member of the set through all permutation\n",
    "    functions, and set the `ith` position of `vec` to the `ith` permutation\n",
    "    function's output if that output is smaller than `vec[i]`.\n",
    "'''\n",
    "def minhash(doc):\n",
    "    \n",
    "    # initialize a minhash of length N with positive infinity values\n",
    "    doc_shingles = doc[1]\n",
    "    signature_vector = [float('inf') for i in range(N)]\n",
    "\n",
    "    for val in doc_shingles:\n",
    "\n",
    "        # ensure doc_shingles is composed of integers\n",
    "        if not isinstance(val, int): val = hash(val)\n",
    "\n",
    "        # loop over each \"permutation function\"\n",
    "        for perm_idx, perm_vals in enumerate(perms):\n",
    "            a, b = perm_vals\n",
    "\n",
    "            # pass `val` through the `ith` permutation function\n",
    "            hash_value = ((a * val + b) % LARGE_PRIME)\n",
    "\n",
    "            # conditionally update the `ith` value of vec\n",
    "            signature_vector[perm_idx] = min(signature_vector[perm_idx], hash_value)\n",
    "            #if signature_vector[perm_idx] > hash_value:\n",
    "                #signature_vector[perm_idx] = hash_value\n",
    "\n",
    "    # the returned vector represents the minimum hash of the set s\n",
    "    return doc[0], signature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "73fa8655-88bc-4e21-b987-b8d88b5f39e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Calculate the Jaccard Similarity beetween two sets\n",
    "'''\n",
    "def jacc_similarity(a,b):\n",
    "    a = set(a)\n",
    "    b = set(b)\n",
    "    return len(a.intersection(b))/len(a.union(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4e91ee76-6db7-49b8-b463-1f9df11cfcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the signature vectors for each doc\n",
    "signatures = docs_shingles.map(minhash)\n",
    "#signatures.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "86e1cb15-4bdb-430b-8fc5-df7c5092e5d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'docs = list(shingles_dict.keys())\\nres = []\\nfor id1 in range(len(docs)):\\n    for id2 in range(id1+1, len(docs)):\\n        sim = jacc_similarity(shingles_dict[docs[id1]], shingles_dict[docs[id2]])\\n        if sim > 0.5:\\n            res.append((docs[id1], docs[id2], sim))'"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''docs = list(shingles_dict.keys())\n",
    "res = []\n",
    "for id1 in range(len(docs)):\n",
    "    for id2 in range(id1+1, len(docs)):\n",
    "        sim = jacc_similarity(shingles_dict[docs[id1]], shingles_dict[docs[id2]])\n",
    "        if sim > 0.5:\n",
    "            res.append((docs[id1], docs[id2], sim))'''\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fc923622-585e-4901-9743-de6148157824",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sign1 = signatures.filter(lambda line: line[0] == \"2344137\")\n",
    "#sign2 = signatures.filter(lambda line: line[0] == \"8355881\")\n",
    "#sign1.take(2)\n",
    "#jaccard_similarity = jacc_similarity(list(sign1.collect()[0][1]), list(sign2.collect()[0][1]))\n",
    "#jaccard_similarity\n",
    "#signs =  [set(sign) for doc,sign in signatures.collect()]\n",
    "#print(jacc_similarity(signs[5],signs[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "afa6b798-fb97-41ee-ba27-56b2c7dab553",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    check if two lists have in common, at least, one element\n",
    "'''\n",
    "def common_data(list1, list2):\n",
    "    result = False\n",
    "    # traverse in the 1st list\n",
    "    for x in list1:\n",
    "  \n",
    "        # traverse in the 2nd list\n",
    "        for y in list2:\n",
    "    \n",
    "            # if one common\n",
    "            if sorted(x) == sorted(y):\n",
    "                result = True\n",
    "                return result \n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1dfb5e1f-6887-43eb-a32d-f718829fe3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Get similar pairs of docs - \"candidates\"\n",
    "'''\n",
    "def get_candidates(bands):\n",
    "    bands_processed = []\n",
    "    pairs_candidates = []\n",
    "    docs = list(bands.keys())\n",
    "    for i1 in range(len(docs)):\n",
    "        for i2 in range(i1+1, len(docs)):\n",
    "            band1 = bands[docs[i1]]\n",
    "            band2 = bands[docs[i2]]\n",
    "            if common_data(band1, band2):\n",
    "                sign1 = signatures_dict[docs[i1]]\n",
    "                sign2 = signatures_dict[docs[i2]]\n",
    "                jaccard_similarity = jacc_similarity(sign1, sign2)\n",
    "                pairs_candidates.append((docs[i1],docs[i2],jaccard_similarity))\n",
    "                    \n",
    "    return pairs_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "7fefebf0-cd0a-426a-94e9-0650f663dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Bands creation\n",
    "'''\n",
    "def split_vector(doc, b=20, r=5):\n",
    "    signature = doc[1]\n",
    "    # code splitting signature in b parts\n",
    "    subvecs = []\n",
    "    for i in range(0, len(signature), r):\n",
    "        subvecs.append(signature[i : i+r])\n",
    "    return doc[0], subvecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e39df8-959e-4562-9bc9-74d3f7a5f61b",
   "metadata": {},
   "source": [
    "### Ex: 2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "230c45e1-46a5-4c44-936e-02db72006a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    Find as candidates at least 99.5% of pairs with 80% similarity and less than 5% of pairs with 40%\n",
    "    similarity.\n",
    "'''\n",
    "\n",
    "b = 20 # Bands\n",
    "r = 5  # Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a46f4676-fb87-4e27-964d-0a6e5bfc0b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test\n",
    "signatures_dict = { doc:sign for doc,sign in signatures.collect() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "feb6c8b7-4ee0-4aa4-8253-ccc60e3e8324",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = signatures.map(lambda line: split_vector(line, b, r))\n",
    "#bands.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "d044cc93-3030-479c-80d2-9caf2479ca59",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands_dict = { doc:band for doc,band in bands.collect() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "0ebdd2d8-c383-4e83-b7ef-1e46e7ce46a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "sim_candidates = get_candidates(bands_dict)\n",
    "print(len(sim_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "14180601-58f3-4570-8f4f-125ab409818c",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_pairs_rdd = sc.parallelize(sim_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "f4e8a265-4a78-45af-83f9-d5f69a3b25df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('31186339', '34556339', 0.9692307692307692),\n",
       " ('31186339', '75686339', 0.9844961240310077),\n",
       " ('31186339', '31185639', 1.0),\n",
       " ('31186339', '31186567', 0.9844961240310077)]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_pairs_rdd.take(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deea352b-62b2-4239-b681-d6e304965252",
   "metadata": {},
   "source": [
    "### Ex: 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "cac2bc44-dc3d-4af5-8e2a-22a8d5cce897",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    Given a movie, returns all other movies that are at least 80% similar in terms of their plots but no more than 98%\n",
    "'''\n",
    "def similar_movies(movie, similar_candidates, treshold=0.8):\n",
    "    sim_movies = []\n",
    "    for m in similar_candidates:\n",
    "        if (movie == m[0]) and m[2]>0.8 and m[2]<0.98:\n",
    "            sim_movies.append(m[1])\n",
    "        if (movie == m[1]) and m[2]>0.8 and m[2]<0.98:\n",
    "            sim_movies.append(m[0])\n",
    "            \n",
    "    return sim_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2c0c1a99-6147-4fac-bd27-192ac32f3793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Movies similar to 31186339: ['34556339']\n"
     ]
    }
   ],
   "source": [
    "# Similar movies\n",
    "movie = \"31186339\"\n",
    "sim_movies = similar_movies(movie, sim_candidates)\n",
    "print(\"Movies similar to {}: {}\".format(movie, sim_movies))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72a88b9-32bf-46be-902c-8ad070fae070",
   "metadata": {},
   "source": [
    "### Ex: 2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "b07f0659-a848-4597-9c7a-731ef095077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    Get False Positives rate\n",
    "'''\n",
    "def fp_evaluation(signs_dict, sim_candidates):\n",
    "    fp = 0\n",
    "    for cand in sim_candidates:\n",
    "        doc1, doc2, sim = cand\n",
    "        shingle1 = signs_dict[doc1]\n",
    "        shingle2 = signs_dict[doc2]\n",
    "        real_similarity = jacc_similarity(shingle1,shingle2)\n",
    "\n",
    "        if sim > 0.8 and real_similarity < 0.8: fp+=1\n",
    "\n",
    "    return (fp/len(sim_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "df6fb932-d9c7-42e3-842e-99d2cebcc3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "    Get False Negatives rate\n",
    "'''\n",
    "def fn_evaluation(signs_dict, sim_candidates):\n",
    "    fn = 0\n",
    "    total_candidates = 0\n",
    "    doc_candidates = []\n",
    "    docs = list(signs_dict.keys())\n",
    "    for id1 in range(len(docs)):\n",
    "        for id2 in range(id1+1, len(docs)):\n",
    "            sig1 = signs_dict[docs[id1]]\n",
    "            sig2 = signs_dict[docs[id2]]\n",
    "            similarity_sig = jacc_similarity(sig1,sig2)\n",
    "            total_candidates += 1\n",
    "            if similarity_sig > 0.8: \n",
    "                doc_candidates.append((docs[id1],docs[id2]))\n",
    "    \n",
    "    false_negatives = len(set(sim_candidates) - set(doc_candidates))\n",
    "    return (fn/total_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "7485580c-1851-4992-9a89-a0d1731a7e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP eval:  0.0\n"
     ]
    }
   ],
   "source": [
    "# FP rate\n",
    "fp_eval = fp_evaluation(signatures_dict, sim_candidates)\n",
    "print(\"FP eval: \",fp_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "be000536-70ff-4bd8-babc-cb8ffa6b7f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FN eval:  0.0\n"
     ]
    }
   ],
   "source": [
    "# FN rate\n",
    "fn_eval = fn_evaluation(signatures_dict, sim_candidates)\n",
    "print(\"FN eval: \",fn_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9975e3e8-c602-430b-9f98-c532d2e3e92d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
