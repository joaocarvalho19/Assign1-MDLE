{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dee8c8b-ba22-445a-bc43-a702356d71e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from datetime import datetime\n",
    "import operator\n",
    "import hashlib\n",
    "import time\n",
    "import re\n",
    "import sys\n",
    "import random\n",
    "\n",
    "# Picking the biggest prime that coems after N shingles (used function to calculate for the given dataset) \n",
    "# https://www.calculatorsoup.com/calculators/math/prime-number-calculator.php\n",
    "LARGE_PRIME = 75874811\n",
    "RANDOM_ARRAY = [(random.randint(0,500), random.randint(0,500)) for i in range(0,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0cb8244-ee23-4535-bc22-a6afced4788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hashing of the string into an int, so we maintain order in shingles\n",
    "def str_to_hashint(string):\n",
    "    return abs(hash(string)) % (10 ** 8)\n",
    "\n",
    "# Definition of hash functions, a and b are random in both functions\n",
    "def h1(x,a,b): \n",
    "    h1_array = []\n",
    "    for value in x:\n",
    "        h1_array.append((a*str_to_hashint(value) + b) % LARGE_PRIME)\n",
    "    return min(h1_array)\n",
    "\n",
    "# Turn document plot into set of shingles\n",
    "def shingling(document,k=9):\n",
    "    shingles = set()\n",
    "    plot_shingles = re.split('',document[1].lower())\n",
    "    for idx in range(len(plot_shingles)-k):\n",
    "        shingle = ''.join(plot_shingles[idx:idx+k])\n",
    "        shingles.add(shingle)\n",
    "    \n",
    "    return document[0],shingles\n",
    "\n",
    "# This function receives a set of Shingles and should return a signature matrix\n",
    "# This was we generate the 100 hash functions, a clever way\n",
    "def minhash(document, k=100):\n",
    "    x = document[1]\n",
    "    signature_matrix = []\n",
    "    for i in range(0,k):\n",
    "        a,b = RANDOM_ARRAY[i]\n",
    "        h = h1(x,a,b)\n",
    "        signature_matrix.append(h)\n",
    "    return document[0],signature_matrix\n",
    "\n",
    "# Function used to Hash a given band into a bucket\n",
    "def hash_lsh(band): \n",
    "    h1_array = []\n",
    "    for value in band:\n",
    "        h1_array.append((421*value + 16) % 1013)\n",
    "    return min(h1_array)\n",
    "\n",
    "# LSH, receives signature_matrix, devolves candidate pairs\n",
    "def lsh(documents, r=5, b=20):\n",
    "    buckets = []\n",
    "    signature = documents[1]\n",
    "    # iterate over each column (movie) and calculate the hash based on a given band portion\n",
    "    # This band portion is given by the rows in each band\n",
    "    for idx in range(0,b):\n",
    "        if idx*r > len(signature): break \n",
    "        max_id = min(idx * r + r, len(signature))\n",
    "        bucket = hash_lsh(signature[idx*r:max_id])\n",
    "        buckets.append(bucket)\n",
    "\n",
    "    return documents[0],buckets\n",
    "\n",
    "# This pipeline evaluates candidate pairs, and returns them\n",
    "def test_lsh(signature_matrix, r=5, b=20):\n",
    "    buckets = {}\n",
    "    candidate_pairs = []\n",
    "    # iterate over each column (movie) and calculate the hash based on a given band portion\n",
    "    # This band portion is given by the rows in each band\n",
    "    for signature in signature_matrix.items():\n",
    "        doc, bucket = lsh(signature, r, b)\n",
    "        for doc2, bucket_list in buckets.items():\n",
    "            for i in range(len(bucket)):\n",
    "                if bucket_list[i] == bucket[i]: # This means its a candidate pair\n",
    "                    similar_pair = similarity(signature[1], signature_matrix[doc2])\n",
    "                    candidate_pairs.append((doc,doc2,similar_pair))\n",
    "                    break  \n",
    "        buckets[doc] = bucket\n",
    "\n",
    "    # This returns candidate_pairs\n",
    "    return candidate_pairs\n",
    "\n",
    "# Given a pair, return its similarity, calculated with 1-jaccard distance\n",
    "def similarity(sig1, sig2): \n",
    "    intersection = len(list(set(sig1).intersection(sig2)))\n",
    "    union = (len(sig1) + len(sig2)) - intersection\n",
    "    jacc = float(intersection) / union\n",
    "    return jacc\n",
    "\n",
    "def calculate_fp_rate(matrix, similar_pairs):\n",
    "    fp = 0\n",
    "    for pair in similar_pairs:\n",
    "        doc1, doc2, sim1 = pair\n",
    "        shingles1 = matrix[doc1]\n",
    "        shingles2 = matrix[doc2]\n",
    "        sm = similarity(shingles1,shingles2)\n",
    "\n",
    "        if sim1 > 0.8 and sm < 0.8: fp+=1\n",
    "\n",
    "    return (fp/len(similar_pairs))\n",
    "\n",
    "def calculate_fn_rate(matrix, similar_pairs):\n",
    "    fn = 0\n",
    "    total_pairs = 0\n",
    "    doc_pairs = []\n",
    "    docs = list(matrix.keys())\n",
    "    for id1 in range(len(docs)):\n",
    "        for id2 in range(id1+1, len(docs)):\n",
    "            sig1 = matrix[docs[id1]]\n",
    "            sig2 = matrix[docs[id2]]\n",
    "            similarity_sig = similarity(sig1,sig2)\n",
    "            total_pairs += 1\n",
    "            if similarity_sig > 0.8: \n",
    "                doc_pairs.append((docs[id1],docs[id2]))\n",
    "    \n",
    "    false_negatives = len(set(similar_pairs) - set(doc_pairs))\n",
    "    return (fn/total_pairs)\n",
    "\n",
    "\n",
    "# This function evaluates\n",
    "def return_similar(target_movie, movies):\n",
    "    similar_movies = []\n",
    "    for movie in movies:\n",
    "        if (target_movie == movie[0]) and movie[2]>0.8 and movie[2]<0.98:\n",
    "            similar_movies.append(movie[0])\n",
    "        if (target_movie == movie[1]) and movie[2]>0.8 and movie[2]<0.98:\n",
    "            similar_movies.append(movie[1])\n",
    "    return similar_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f470b58-434d-43c0-a905-c0f4e24e5e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkContext(appName=\"MovieRecommendation\")\n",
    "log4jLogger = sc._jvm.org.apache.log4j\n",
    "LOGGER = log4jLogger.LogManager.getLogger(\"RESULTS\")\n",
    "LOGGER.info(\"pyspark script logger initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1bece37f-f46b-4fa2-b955-0baedb5714d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial pipeline of shingling, minhashing and then performing LSH\n",
    "textfile = sc.textFile(\"assign1/data/small_plot_sum.txt\")\n",
    "signatures = textfile.map(lambda line: re.split('\\t', line.lower())) \\\n",
    "                            .map(shingling) \\\n",
    "                            .map(minhash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5c7c54e2-e60b-4cda-a191-eda9ed897444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the signatures \"matrix\", so we can evaluate it on the LSH Function\n",
    "signatures_matrix = { doc:buckets for doc,buckets in signatures.collect() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d0edac7-cea9-4440-ae39-21039128ee56",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m similar_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_lsh\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignatures_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mtest_lsh\u001b[0;34m(signature_matrix, r, b)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc2, bucket_list \u001b[38;5;129;01min\u001b[39;00m buckets\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(bucket)):\n\u001b[0;32m---> 64\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m bucket_list[i] \u001b[38;5;241m==\u001b[39m \u001b[43mbucket\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m: \u001b[38;5;66;03m# This means its a candidate pair\u001b[39;00m\n\u001b[1;32m     65\u001b[0m             similar_pair \u001b[38;5;241m=\u001b[39m similarity(signature[\u001b[38;5;241m1\u001b[39m], signature_matrix[doc2])\n\u001b[1;32m     66\u001b[0m             candidate_pairs\u001b[38;5;241m.\u001b[39mappend((doc,doc2,similar_pair))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "similar_pairs = test_lsh(signatures_matrix, 5, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56326bb6-01a4-4eb5-ae40-3e0a09d6cd89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2231378', '20663735', 0.02040816326530612),\n",
       " ('5272176', '20663735', 0.0),\n",
       " ('2462689', '20663735', 0.005025125628140704),\n",
       " ('2462689', '2231378', 0.0),\n",
       " ('2462689', '1952976', 0.005025125628140704),\n",
       " ('18188932', '23890098', 0.0),\n",
       " ('18188932', '5272176', 0.0),\n",
       " ('1335380', '20532852', 0.0),\n",
       " ('1480747', '24225279', 0.005025125628140704),\n",
       " ('24448645', '1952976', 0.015228426395939087)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_pairs[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7330abbd-2ffe-4943-a6d5-7817026f7683",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_pairs_rdd = sc.parallelize(similar_pairs) \\\n",
    "                            .sortBy(lambda line: -line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe6a4bbe-e084-4577-8820-3e1e45f795bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar = return_similar('23890098', similar_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ba06723-e738-4b54-b845-5b26485a68c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('5335934', '6167400', 0.15606936416184972),\n",
       " ('4543480', '4356664', 0.13636363636363635),\n",
       " ('21032415', '4356664', 0.12359550561797752),\n",
       " ('4543480', '21032415', 0.12359550561797752),\n",
       " ('74868', '7429667', 0.12359550561797752),\n",
       " ('1405743', '4543480', 0.11731843575418995),\n",
       " ('161915', '25807103', 0.10497237569060773),\n",
       " ('1405743', '4356664', 0.10497237569060773),\n",
       " ('8355881', '4543480', 0.10497237569060773),\n",
       " ('1814089', '1838882', 0.09289617486338798)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_pairs_rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760bcc45-fa3d-4ab2-87bf-1829e65d3525",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
